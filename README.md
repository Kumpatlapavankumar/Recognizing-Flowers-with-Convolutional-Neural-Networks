# ðŸŒ¸ Flower Classification using Convolutional Neural Networks (CNN)

This project focuses on classifying different types of flowers using a Convolutional Neural Network (CNN) built with TensorFlow and Keras. The goal is to recognize and classify images of flowers into 5 categories: Daisy, Dandelion, Rose, Sunflower, and Tulip. This deep learning model is trained on the [Flowers Recognition dataset](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition) and uses data augmentation techniques to improve performance.

---

## ðŸ“‚ Dataset Overview

- **Source**: Kaggle - [Flowers Recognition](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition)
- **Classes**:
  - Daisy
  - Dandelion
  - Rose
  - Sunflower
  - Tulip
- **Format**: JPEG images
- **Total Size**: ~600 MB

---

## ðŸ”§ Tech Stack

- **Programming Language**: Python
- **Libraries**:
  - `TensorFlow`, `Keras`
  - `OpenCV` (for image preprocessing)
  - `Matplotlib`, `Seaborn` (for visualizations)
  - `NumPy`, `Pandas` (for data handling)

---

## ðŸ§  Model Architecture

```text
Input Image (180x180x3)
â†“
Conv2D (32 filters) â†’ ReLU â†’ MaxPooling2D
â†“
Conv2D (64 filters) â†’ ReLU â†’ MaxPooling2D
â†“
Conv2D (128 filters) â†’ ReLU â†’ MaxPooling2D
â†“
Flatten
â†“
Dense (128 units) â†’ ReLU
â†“
Dropout (0.5)
â†“
Dense (5 units) â†’ Softmax (Output)
```

- **Optimizer**: Adam
- **Loss Function**: Categorical Crossentropy
- **Metrics**: Accuracy

---

## ðŸ§ª Data Augmentation

To avoid overfitting and improve model generalization, the following augmentations were applied using `ImageDataGenerator`:

- Rotation
- Zoom
- Width & Height Shift
- Horizontal Flip
- Rescaling

---

## ðŸ“Š Visualizations & Analysis

### 1. **Class Distribution**

![Class Distribution](assets/class_distribution.png)

The dataset is slightly imbalanced, with `Dandelion` having the most images.

---

### 2. **Sample Images**

![Sample Images](assets/sample_images.png)

Random samples of each flower class after augmentation.

---

### 3. **Training & Validation Accuracy**

![Training Accuracy](assets/training_accuracy.png)

The model converged well, with training accuracy reaching **~95%** and validation accuracy around **~88%**.

---

### 4. **Training & Validation Loss**

![Training Loss](assets/training_loss.png)

Loss steadily decreased, indicating a stable training process.

---

### 5. **Confusion Matrix**

![Confusion Matrix](assets/confusion_matrix.png)

The model performs best on **Dandelion** and **Sunflower**, with some misclassifications among similar-looking classes like `Daisy` and `Tulip`.

---

## âœ… Final Results

| Metric            | Value        |
|-------------------|--------------|
| Training Accuracy | ~95%         |
| Validation Accuracy | ~88%      |
| Test Accuracy     | ~87%         |

---

## ðŸš€ How to Run the Project

1. **Clone the repo**:
   ```bash
   git clone https://github.com/your-username/flower-classification-cnn.git
   cd flower-classification-cnn
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Download the dataset**:
   Download from [Kaggle](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition) and extract it to the project folder.

4. **Run the notebook**:
   ```bash
   jupyter notebook Recognizing\ Flowers\ with\ Convolutional\ Neural\ Networks.ipynb
   ```

---

## ðŸ”® Future Improvements

- Implement transfer learning using `EfficientNet`, `ResNet`, or `VGG16`
- Hyperparameter tuning using `KerasTuner` or `Optuna`
- Deploy the model using **Streamlit** or **Flask**
- Convert the model to TensorFlow Lite for mobile applications

---

## ðŸ§¾ License

This project is open-source and available under the [MIT License](LICENSE).

---

## ðŸ™Œ Acknowledgements

- Kaggle for the flower dataset
- TensorFlow & Keras documentation
